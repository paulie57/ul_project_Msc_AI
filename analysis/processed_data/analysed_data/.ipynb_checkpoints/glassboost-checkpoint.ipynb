{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fe5486d-5249-4319-958b-ba5552e524ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tight_layout\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ##SETTING PARAMS FOR MATPLOTLIB FIGURES\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mrcParams\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfigure.figsize\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m6\u001b[39m),\n\u001b[1;32m      5\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxes.facecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxes.edgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes.prop_cycle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mcycler(color\u001b[38;5;241m=\u001b[39msns\u001b[38;5;241m.\u001b[39mcolor_palette(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolorblind\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m##set font size\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "#sns.set_palette('colorblind')\n",
    "from matplotlib.pyplot import tight_layout\n",
    "# ##SETTING PARAMS FOR MATPLOTLIB FIGURES\n",
    "plt.rcParams.update({\"figure.figsize\": (6, 6),\n",
    "                 \"axes.facecolor\": \"white\",\n",
    "                 \"axes.edgecolor\": \"black\"})\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=sns.color_palette('colorblind'))\n",
    "##set font size\n",
    "font = {'family': 'sans-serif',\n",
    "       'weight': 'normal',\n",
    "       'size': 14}\n",
    "plt.rc('font', **font)\n",
    "# ##PANDAS PLOTTING\n",
    "pd.plotting.register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644b71f4-08b0-42f3-8518-9b27623d6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "import shutil\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39222a-edb4-429e-bb29-c4c2deb28a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_glass= \"/home/paulharford/college/project/project_data/processed/WEATHERED_merged_v2.csv\"\n",
    "full_path_glass = os.path.abspath(merged_glass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1576448-d336-482e-9d94-fda27acdc979",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_glass = pd.read_csv(full_path_glass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd81513-85a8-485c-a299-5c1715fe10a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_glass.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c47438-3c01-4e04-9aee-105f34701d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import warnings\n",
    "## Suppress all FutureWarning messages\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "pathdic={}\n",
    "pathdic['project_root'] = '/home/paulharford/college/project/ul_project_Msc_AI/analysis/processed_data/analysed_data/glassboost'\n",
    "pathdic['sprint_root'] = os.getcwd()\n",
    "###CREATE DATASET AND OUTPUTS DIRECTORIES IF NOT EXISTING\n",
    "mdirs = ['dataset', 'outputs', 'results']\n",
    "for mdir in mdirs:\n",
    "\tif not os.path.exists(os.path.join(pathdic['project_root'], mdir)):\n",
    "\t\tos.makedirs(os.path.join(pathdic['project_root'] , mdir))\n",
    "\t\tpathdic[mdir]=os.path.join(pathdic['project_root'], mdir)\n",
    "\telse:\n",
    "\t\tpathdic[mdir]=os.path.join(pathdic['project_root'], mdir)\n",
    "        \n",
    "def create_directory(fname):\n",
    "\t\"\"\"\n",
    "\tCreate a folder if it doesn't already exist.\n",
    "\t:param fname:path and directory name\n",
    "\t:return:\n",
    "\t\"\"\"\n",
    "\tif not os.path.exists(fname):\n",
    "\t\tos.makedirs(fname)\n",
    "\n",
    "def create_single_subdir(fname=None, path_to_f=None):\n",
    "\tnpth = os.path.join(path_to_f, fname)\n",
    "\tif not os.path.exists(npth):\n",
    "\t\tos.makedirs(npth)\n",
    "\treturn npth\n",
    "\n",
    "def create_single_results_subdir(fname=None, path_to_f=None):\n",
    "\tnpth = os.path.join(path_to_f, fname)\n",
    "\ttry:\n",
    "\t\t##DELETE THE FOLDER\n",
    "\t\tshutil.rmtree(npth)\n",
    "\t\tos.makedirs(npth)\n",
    "\texcept WindowsError:\n",
    "\t\tos.makedirs(npth)\n",
    "\treturn npth\n",
    "\n",
    "def create_multi_dirs(fname=None, pathdic=None, listdirs=None):\n",
    "\tfor d in listdirs:\n",
    "\t\t###create the dir\n",
    "\t\tcreate_directory(os.path.join(pathdic[d], fname))\n",
    "\t\tif 'figures' in d:\n",
    "\t\t\t###update pathdic\n",
    "\t\t\tpathdic['savefig'] = os.path.join(pathdic[d], fname)\n",
    "\t\telif 'dfs' in d:\n",
    "\t\t\tpathdic['savedf'] = os.path.join(pathdic[d], fname)\n",
    "\t\telse:\n",
    "\t\t\tpathdic[d] = os.path.join(pathdic[d], fname)\n",
    "\treturn pathdic\n",
    "\n",
    "def split_long_names(name):\n",
    "\tsplit_pos = name.rfind(' ', 0, 25)\n",
    "\tif split_pos != -1:\n",
    "\t\treturn name[:split_pos] + '\\n' + name[split_pos + 1:]\n",
    "\telse:\n",
    "\t\treturn name\n",
    "\n",
    "def round_up(numerator, denominator):\n",
    "\treturn np.ceil(numerator/denominator) * denominator\n",
    "\n",
    "\n",
    "def apply_min_ticks(ax, min_ticks=6):\n",
    "\tax.xaxis.set_major_locator(ticker.MaxNLocator(nbins=min_ticks, prune=None))\n",
    "\tax.yaxis.set_major_locator(ticker.MaxNLocator(nbins=min_ticks, prune=None))\n",
    "\n",
    "def specificity_score(y_true, y_pred):\n",
    "\ttn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\treturn tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "\n",
    "def img_from_df(df=None, path_out=None, filename=None):\n",
    "\tdf = df.applymap(lambda x: f\"{x:.4g}\" if isinstance(x, (int, float)) else x)\n",
    "\t####FORMAT INDEX FROM 1 TO N\n",
    "\tdf.index = range(1, len(df.index) + 1)\n",
    "\tdf.index.name = 'index'\n",
    "\t###ENSURE INDEX IS PRINTED\n",
    "\tdf.reset_index(inplace=True)\n",
    "\tfig, ax = plt.subplots(figsize=(df.shape[1] * 2, df.shape[0] * 0.25))\n",
    "\tax.axis('off')\n",
    "\n",
    "\ttable = ax.table(cellText=df.values, colLabels=df.columns, loc='center', cellLoc='center')\n",
    "\ttable.auto_set_font_size(False)\n",
    "\ttable.set_fontsize(12)\n",
    "\ttable.auto_set_column_width(col=list(range(len(df.columns))))\n",
    "\ttable.scale(1.2, 1.2)\n",
    "\n",
    "\tplt.savefig(os.path.join(path_out, f'{filename}.png'), bbox_inches='tight', dpi=300)\n",
    "\tplt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4e4d4a-2c12-4f70-98e9-fc650205f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cart_gridsearch(X=None, y=None,\n",
    "\t\t\t\t\t\timportance_df=None,\n",
    "\t\t\t\t\t\ttop_n_list=None,\n",
    "\t\t\t\t\t\tdepth_list=None,\n",
    "\t\t\t\t\t\tpath_out=None,\n",
    "\t\t\t\t\t\tlabel=None):\n",
    "\tif top_n_list is None:\n",
    "\t\ttop_n_list = [2, 3, 5, 7]\n",
    "\n",
    "\tif depth_list is None:\n",
    "\t\tdepth_list = [3, 4, 5]\n",
    "\n",
    "\tcart_results = []\n",
    "\ttop_features_sorted = list(importance_df.sort_values('Gain', ascending=False)['Feature'])\n",
    "\n",
    "\tfor n in top_n_list:\n",
    "\t\tif n > len(top_features_sorted):\n",
    "\t\t\tcontinue\n",
    "\t\tselected_feats = top_features_sorted[:n]\n",
    "\t\tX_top = X[selected_feats]\n",
    "\n",
    "\t\tfor depth in depth_list:\n",
    "\t\t\tX_train, X_test, y_train, y_test = train_test_split(X_top, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\t\t\tcart = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "\t\t\tcart.fit(X_train, y_train)\n",
    "\t\t\ty_pred = cart.predict(X_test)\n",
    "\n",
    "\t\t\t##SAVE CART MODELS\n",
    "\t\t\tmodel_filename = f'cart_model_{label}_top{n}_depth{depth}.pkl'\n",
    "\t\t\twith open(os.path.join(path_out, model_filename), 'wb') as f:\n",
    "\t\t\t\tpickle.dump(cart, f)\n",
    "\n",
    "\t\t\tacc = accuracy_score(y_test, y_pred)\n",
    "\t\t\tprec = precision_score(y_test, y_pred)\n",
    "\t\t\trec = recall_score(y_test, y_pred)\n",
    "\t\t\tspec = specificity_score(y_test, y_pred)\n",
    "\n",
    "\t\t\tcart_results.append({\n",
    "\t\t\t\t'label': label,\n",
    "\t\t\t\t'top_n_features': n,\n",
    "\t\t\t\t'max_depth': depth,\n",
    "\t\t\t\t'accuracy': acc,\n",
    "\t\t\t\t'precision': prec,\n",
    "\t\t\t\t'recall': rec,\n",
    "\t\t\t\t'specificity': spec,\n",
    "\t\t\t})\n",
    "\n",
    "\tcart_df = pd.DataFrame(cart_results)\n",
    "\tcart_df.to_csv(os.path.join(path_out, f'cart_results_{label}.csv'), index=False)\n",
    "\n",
    "\t###CREATE IMAGE OF THE GRID RESULTS\n",
    "\timg_from_df(df=cart_df,\n",
    "\t\t\t\tpath_out=path_out,\n",
    "\t\t\t\tfilename=f'cart_results_{label}')\n",
    "\n",
    "\t###HEATMAP\n",
    "\t# Heatmaps\n",
    "\tfor metric, cmap in zip(['accuracy', 'precision', 'recall', 'specificity'],\n",
    "\t\t\t\t\t\t\t['YlGnBu', 'Oranges', 'Purples', 'Blues']):\n",
    "\t\tpivot = cart_df.pivot(index='max_depth', columns='top_n_features', values=metric)\n",
    "\t\tplt.figure(figsize=(6, 6), constrained_layout=True)\n",
    "\t\tsns.heatmap(pivot, annot=True, fmt=\".2f\", cmap=cmap, cbar_kws={'label': metric})\n",
    "\t\tplt.title(f\"CART {metric.capitalize()} Heatmap - {label}\")\n",
    "\t\tplt.xlabel(\"Top n Features\")\n",
    "\t\tplt.ylabel(\"Max Depth\")\n",
    "\t\tplt.savefig(os.path.join(path_out, f'xgb_heatmap_{metric}_{label}.png'), dpi=300)\n",
    "\t\tplt.close()\n",
    "\n",
    "\treturn cart_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f28e4c1-44a3-4fda-b858-39f1d6cdc6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xgboost_gridsearch(X=None,\n",
    "\t\t\t\t\t\t   y=None,\n",
    "\t\t\t\t\t\t   param_grid=None,\n",
    "\t\t\t\t\t\t   path_out=None,\n",
    "\t\t\t\t\t\t   metric=None,\n",
    "\t\t\t\t\t\t   label='default'):\n",
    "\tif X is None or y is None or X.shape[0] == 0:\n",
    "\t\traise ValueError(\"Input features X or target y are empty or undefined.\")\n",
    "\n",
    "\txgb_grid_results = []\n",
    "\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\tfor max_depth, n_estimators in product(param_grid['max_depth'], param_grid['n_estimators']):\n",
    "\t\tmodel = XGBClassifier(\n",
    "\t\t\t#use_label_encoder=False,\n",
    "\t\t\teval_metric='logloss',\n",
    "\t\t\tmax_depth=max_depth,\n",
    "\t\t\tn_estimators=n_estimators,\n",
    "\t\t\trandom_state=42\n",
    "\t\t)\n",
    "\t\tmodel.fit(X_train, y_train)\n",
    "\t\ty_pred = model.predict(X_test)\n",
    "\t\tspec = specificity_score(y_test, y_pred)\n",
    "\n",
    "\t\txgb_grid_results.append({\n",
    "\t\t\t'filter': label,\n",
    "\t\t\t'max_depth': max_depth,\n",
    "\t\t\t'n_estimators': n_estimators,\n",
    "\t\t\t'accuracy': accuracy_score(y_test, y_pred),\n",
    "\t\t\t'precision': precision_score(y_test, y_pred),\n",
    "\t\t\t'recall': recall_score(y_test, y_pred),\n",
    "\t\t\t'specificity':spec,\n",
    "\t\t})\n",
    "\n",
    "\t# Save grid results\n",
    "\txgb_df = pd.DataFrame(xgb_grid_results)\n",
    "\txgb_df.to_csv(os.path.join(path_out, f'xgb_grid_results_{label}.csv'), index=False)\n",
    "\n",
    "\t###CREATE IMAGE OF THE GRID RESULTS\n",
    "\timg_from_df(df=xgb_df,\n",
    "\t\t\t\tpath_out=path_out,\n",
    "\t\t\t\tfilename='xgb_grid_results_table')\n",
    "\n",
    "\t# Heatmaps\n",
    "\tfor metric, cmap in zip(['accuracy', 'precision', 'recall', 'specificity'], ['YlGnBu', 'Oranges', 'Purples', 'Blues']):\n",
    "\t\tpivot = xgb_df.pivot(index='max_depth', columns='n_estimators', values=metric)\n",
    "\t\tplt.figure(figsize=(6, 6), constrained_layout=True)\n",
    "\t\tsns.heatmap(pivot, annot=True, fmt=\".2f\", cmap=cmap, cbar_kws={'label': metric})\n",
    "\t\tplt.title(f\"XGBoost {metric.capitalize()} Heatmap - {label}\")\n",
    "\t\tplt.xlabel(\"n_estimators\")\n",
    "\t\tplt.ylabel(\"max_depth\")\n",
    "\t\tplt.savefig(os.path.join(path_out, f'xgb_heatmap_{metric}_{label}.png'), dpi=300)\n",
    "\t\tplt.close()\n",
    "\n",
    "\t# Train best model\n",
    "\tbest = xgb_df.sort_values(by=metric, ascending=False).iloc[0]\n",
    "\tbest_model = XGBClassifier(\n",
    "\t\t#use_label_encoder=False,\n",
    "\t\teval_metric='logloss',\n",
    "\t\tmax_depth=int(best['max_depth']),\n",
    "\t\tn_estimators=int(best['n_estimators']),\n",
    "\t\trandom_state=42\n",
    "\t)\n",
    "\tbest_model.fit(X_train, y_train)\n",
    "\n",
    "\t# SHAP\n",
    "\texplainer = shap.Explainer(best_model)\n",
    "\tshap_values = explainer(X_test)\n",
    "\tshap.plots.beeswarm(shap_values, max_display=15, order=shap_values.abs.max(0), show=False)\n",
    "\tplt.savefig(os.path.join(path_out, f'SHAP_best_{label}.png'), dpi=300, bbox_inches='tight')\n",
    "\tplt.close()\n",
    "\n",
    "\t# Feature importance\n",
    "\tbooster = best_model.get_booster()\n",
    "\tfig, ax = plt.subplots(figsize=(12, 8))\n",
    "\tplot_importance(booster, importance_type='gain', max_num_features=15, ax=ax)\n",
    "\tplt.title(f\"Top Features by Gain (Best XGBoost) - {label}\")\n",
    "\tplt.savefig(os.path.join(path_out, f'top_features_by_gain_best_{label}.png'), dpi=300, bbox_inches='tight')\n",
    "\tplt.close()\n",
    "\n",
    "\timportance_df = booster.get_score(importance_type='gain')\n",
    "\timportance_df_df = pd.DataFrame(list(importance_df.items()), columns=['Feature', 'Gain'])\n",
    "\timportance_df_df = importance_df_df.sort_values(by='Gain', ascending=False)\n",
    "\timportance_df_df['Cumulative Gain'] = importance_df_df['Gain'].cumsum()\n",
    "\timportance_df_df['Cumulative Gain %'] = importance_df_df['Cumulative Gain'] / importance_df_df['Gain'].sum() *100\n",
    "\timportance_df_df.to_csv(os.path.join(path_out, 'importance_df.csv'), index=False)\n",
    "\n",
    "\t###CREATE IMAGE OF THE IMPORTANCE TABLE\n",
    "\timg_from_df(df=importance_df_df,\n",
    "\t\t\t\tpath_out=path_out,\n",
    "\t\t\t\tfilename='importance_df_table')\n",
    "\n",
    "\treturn best_model, importance_df_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfaf686-58f2-4d29-b01a-187bffec1e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046f64b0-1694-4ada-b7af-95c46645777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_glass.drop('hip_fracture_count', axis=1)\n",
    "y = merged_glass['hip_fracture_count']\n",
    "\n",
    "# Binary classification: fracture vs no fracture\n",
    "y_binary = (y > 0).astype(int)\n",
    "\n",
    "print(\"Columns in X:\")\n",
    "print(X.columns.tolist())\n",
    "print(\"\\nData types:\")\n",
    "print(X.dtypes)\n",
    "\n",
    "# Option 1: Drop the date column and encode everything else\n",
    "X_processed = X.copy()\n",
    "\n",
    "# Drop date column if it exists\n",
    "if 'date' in X_processed.columns:\n",
    "    X_processed = X_processed.drop('date', axis=1)\n",
    "\n",
    "# Check for any remaining object columns\n",
    "object_cols = X_processed.select_dtypes(include=['object']).columns\n",
    "print(f\"\\nObject columns to encode: {object_cols.tolist()}\")\n",
    "\n",
    "# Encode all object columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "for col in object_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_processed[col] = le.fit_transform(X_processed[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Verify all columns are numeric\n",
    "print(\"\\nData types after processing:\")\n",
    "print(X_processed.dtypes)\n",
    "print(f\"\\nAny remaining object columns: {X_processed.select_dtypes(include=['object'])}\")\n",
    "\n",
    "dfu = merged_glass[merged_glass['hip_fracture_count'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3ea1e-150a-4ecd-9989-ce24c0d59cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "### MODELLING ASSESSMENT\n",
    "##########\n",
    "###RUN XGBOOST ASSESSMENT\n",
    "### XGBoost hyperparameter grid\n",
    "param_grid = {\n",
    "\t'max_depth': [3, 4, 5, 6, 10, 20],\n",
    "\t'n_estimators': [50, 100, 150]\n",
    "}\n",
    "metric = 'specificity'\n",
    "##RUN XGBOOST AND GET BEST MODEL\n",
    "best_model, importance_df = run_xgboost_gridsearch(X=X_processed,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   y=y_binary,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   param_grid=param_grid,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   metric=metric,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   path_out=pathdic['results'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   label='dfk')\n",
    "###save best model to pkl\n",
    "pickle.dump(best_model,\n",
    "\t\t\topen(os.path.join(pathdic['results'], 'XGB_best_model.pkl'), 'wb'))\n",
    "###BASED ON THE BEST XGBOOST MODEL RUN A CART ANALYSIS\n",
    "cart_df = run_cart_gridsearch(X=X_processed,\n",
    "\t\t\t\t\t\t\t  y=y_binary,\n",
    "\t\t\t\t\t\t\t  importance_df=importance_df,\n",
    "\t\t\t\t\t\t\t  top_n_list=[2, 3, 5, 7, 10],\n",
    "\t\t\t\t\t\t\t  depth_list=[3, 4, 5, 6],\n",
    "\t\t\t\t\t\t\t  path_out=pathdic['results'],\n",
    "\t\t\t\t\t\t\t  label='dfk')\n",
    "\n",
    "##SELECT HIGHEST ACCURACY CART MODEL WITH MINIMAL FEATURES AND TREE DEPTH\n",
    "best_cart = cart_df.sort_values(\n",
    "\tby=[metric, 'top_n_features', 'max_depth'],\n",
    "\tascending=[False, True, True]\n",
    ").iloc[0]\n",
    "\n",
    "print(\"Best efficient CART model:\")\n",
    "print(best_cart)\n",
    "###USING CART PREDICT OUTCOMES ON DF UNKNOWN\n",
    "filename = f\"cart_model_{best_cart['label']}_top{int(best_cart['top_n_features'])}_depth{int(best_cart['max_depth'])}.pkl\"\n",
    "filepath = os.path.join(pathdic['results'], filename)\n",
    "\n",
    "# Load the model\n",
    "with open(filepath, 'rb') as f:\n",
    "\tcart_model = pickle.load(f)\n",
    "\n",
    "###GET THE TOP FEATURES ONLY\n",
    "selected_feats = importance_df.sort_values(\n",
    "\t'Gain',\n",
    "\tascending=False).head(int(best_cart['top_n_features']))['Feature'].tolist()\n",
    "X_u = dfu[selected_feats]\n",
    "\n",
    "###PLOT THE  BEST MODEL\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "plot_tree(cart_model, feature_names=selected_feats, class_names=True, filled=True, max_depth=int(best_cart['max_depth']))\n",
    "plt.title(f\"CART Tree - Top {int(best_cart['top_n_features'])} Features - Depth {int(best_cart['max_depth'])}\")\n",
    "plt.savefig(os.path.join(pathdic['results'], f'cart_tree_top{int(best_cart['top_n_features'])}_depth{int(best_cart['max_depth'])}.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "####generate predictions\n",
    "#y_pred = cart_model.predict(X_u)\n",
    "#merged_glass['predicted_outcome'] = merged_glass['hip_fracture_count']\n",
    "##apply predictions to df\n",
    "#df_filtered.loc[df_filtered['hip_fracture_count'].isna(), 'predicted_outcome'] = y_pred\n",
    "###ADD GROUND TRUTH DATA TO PREDICTED\n",
    "##save the df\n",
    "#merged_glass.to_csv(os.path.join(pathdic['results'], 'predictions_df.csv'))\n",
    "#pred_series = merged_glass['predicted_outcome']\n",
    "##save outcomes to txt file\n",
    "#with open(os.path.join(pathdic['results'], 'cart_prediction.txt'), 'w') as f:\n",
    "#\tfor idx, val in pred_series.items():\n",
    "#\t\tf.write(f\"{idx}: {val}\\n\")\n",
    "X_u.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be56407-7b3b-4370-a311-f7ea64b43b38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
