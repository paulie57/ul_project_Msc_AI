{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "644b71f4-08b0-42f3-8518-9b27623d6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "import shutil\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe5486d-5249-4319-958b-ba5552e524ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette('colorblind')\n",
    "from matplotlib.pyplot import tight_layout\n",
    "# ##SETTING PARAMS FOR MATPLOTLIB FIGURES\n",
    "plt.rcParams.update({\"figure.figsize\": (6, 6),\n",
    "                 \"axes.facecolor\": \"white\",\n",
    "                 \"axes.edgecolor\": \"black\"})\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=sns.color_palette('colorblind'))\n",
    "##set font size\n",
    "font = {'family': 'sans-serif',\n",
    "       'weight': 'normal',\n",
    "       'size': 14}\n",
    "plt.rc('font', **font)\n",
    "# ##PANDAS PLOTTING\n",
    "pd.plotting.register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab39222a-edb4-429e-bb29-c4c2deb28a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_glass= \"/home/paulharford/college/project/project_data/processed/WEATHERED_merged_v2.csv\"\n",
    "full_path_glass = os.path.abspath(merged_glass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1576448-d336-482e-9d94-fda27acdc979",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_glass = pd.read_csv(full_path_glass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebd81513-85a8-485c-a299-5c1715fe10a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>date</th>\n",
       "      <th>age_group</th>\n",
       "      <th>gender</th>\n",
       "      <th>hip_fracture_count</th>\n",
       "      <th>weather_event</th>\n",
       "      <th>warning_phenomenon</th>\n",
       "      <th>warning_severity</th>\n",
       "      <th>warning_severity_numeric</th>\n",
       "      <th>counties_in_region</th>\n",
       "      <th>...</th>\n",
       "      <th>red_warning_lag</th>\n",
       "      <th>cold_weather</th>\n",
       "      <th>wind_weather</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>heat_weather</th>\n",
       "      <th>no_adverse_weather</th>\n",
       "      <th>cold_lag</th>\n",
       "      <th>wind_lag</th>\n",
       "      <th>precip_lag</th>\n",
       "      <th>heat_lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HSE Dublin and Midlands</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>65-69</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Wind</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HSE Dublin and Midlands</td>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>60-64</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Wind</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HSE Dublin and Midlands</td>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>65-69</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Wind</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HSE Dublin and Midlands</td>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>70-74</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Wind</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HSE Dublin and Midlands</td>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>75-79</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Wind</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    region        date age_group  gender  hip_fracture_count  \\\n",
       "0  HSE Dublin and Midlands  2014-01-02     65-69  Female                 1.0   \n",
       "1  HSE Dublin and Midlands  2014-01-03     60-64  Female                 0.0   \n",
       "2  HSE Dublin and Midlands  2014-01-03     65-69  Female                 0.0   \n",
       "3  HSE Dublin and Midlands  2014-01-03     70-74  Female                 0.0   \n",
       "4  HSE Dublin and Midlands  2014-01-03     75-79  Female                 0.0   \n",
       "\n",
       "   weather_event warning_phenomenon warning_severity  \\\n",
       "0            1.0               Wind           Yellow   \n",
       "1            1.0               Wind           Yellow   \n",
       "2            1.0               Wind           Yellow   \n",
       "3            1.0               Wind           Yellow   \n",
       "4            1.0               Wind           Yellow   \n",
       "\n",
       "   warning_severity_numeric  counties_in_region  ...  red_warning_lag  \\\n",
       "0                       1.0                   7  ...              0.0   \n",
       "1                       1.0                   7  ...              0.0   \n",
       "2                       1.0                   7  ...              0.0   \n",
       "3                       1.0                   7  ...              0.0   \n",
       "4                       1.0                   7  ...              0.0   \n",
       "\n",
       "   cold_weather  wind_weather  precipitation  heat_weather  \\\n",
       "0             0             1              0             0   \n",
       "1             0             1              0             0   \n",
       "2             0             1              0             0   \n",
       "3             0             1              0             0   \n",
       "4             0             1              0             0   \n",
       "\n",
       "   no_adverse_weather  cold_lag wind_lag  precip_lag  heat_lag  \n",
       "0                   0       0.0      0.0         0.0       0.0  \n",
       "1                   0       0.0      1.0         0.0       0.0  \n",
       "2                   0       0.0      1.0         0.0       0.0  \n",
       "3                   0       0.0      1.0         0.0       0.0  \n",
       "4                   0       0.0      1.0         0.0       0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_glass.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89c47438-3c01-4e04-9aee-105f34701d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import warnings\n",
    "## Suppress all FutureWarning messages\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "pathdic={}\n",
    "pathdic['project_root'] = '/home/paulharford/college/project/ul_project_Msc_AI/analysis/processed_data/analysed_data/glassboost'\n",
    "pathdic['sprint_root'] = os.getcwd()\n",
    "###CREATE DATASET AND OUTPUTS DIRECTORIES IF NOT EXISTING\n",
    "mdirs = ['dataset', 'outputs', 'results']\n",
    "for mdir in mdirs:\n",
    "\tif not os.path.exists(os.path.join(pathdic['project_root'], mdir)):\n",
    "\t\tos.makedirs(os.path.join(pathdic['project_root'] , mdir))\n",
    "\t\tpathdic[mdir]=os.path.join(pathdic['project_root'], mdir)\n",
    "\telse:\n",
    "\t\tpathdic[mdir]=os.path.join(pathdic['project_root'], mdir)\n",
    "        \n",
    "def create_directory(fname):\n",
    "\t\"\"\"\n",
    "\tCreate a folder if it doesn't already exist.\n",
    "\t:param fname:path and directory name\n",
    "\t:return:\n",
    "\t\"\"\"\n",
    "\tif not os.path.exists(fname):\n",
    "\t\tos.makedirs(fname)\n",
    "\n",
    "def create_single_subdir(fname=None, path_to_f=None):\n",
    "\tnpth = os.path.join(path_to_f, fname)\n",
    "\tif not os.path.exists(npth):\n",
    "\t\tos.makedirs(npth)\n",
    "\treturn npth\n",
    "\n",
    "def create_single_results_subdir(fname=None, path_to_f=None):\n",
    "\tnpth = os.path.join(path_to_f, fname)\n",
    "\ttry:\n",
    "\t\t##DELETE THE FOLDER\n",
    "\t\tshutil.rmtree(npth)\n",
    "\t\tos.makedirs(npth)\n",
    "\texcept WindowsError:\n",
    "\t\tos.makedirs(npth)\n",
    "\treturn npth\n",
    "\n",
    "def create_multi_dirs(fname=None, pathdic=None, listdirs=None):\n",
    "\tfor d in listdirs:\n",
    "\t\t###create the dir\n",
    "\t\tcreate_directory(os.path.join(pathdic[d], fname))\n",
    "\t\tif 'figures' in d:\n",
    "\t\t\t###update pathdic\n",
    "\t\t\tpathdic['savefig'] = os.path.join(pathdic[d], fname)\n",
    "\t\telif 'dfs' in d:\n",
    "\t\t\tpathdic['savedf'] = os.path.join(pathdic[d], fname)\n",
    "\t\telse:\n",
    "\t\t\tpathdic[d] = os.path.join(pathdic[d], fname)\n",
    "\treturn pathdic\n",
    "\n",
    "def split_long_names(name):\n",
    "\tsplit_pos = name.rfind(' ', 0, 25)\n",
    "\tif split_pos != -1:\n",
    "\t\treturn name[:split_pos] + '\\n' + name[split_pos + 1:]\n",
    "\telse:\n",
    "\t\treturn name\n",
    "\n",
    "def round_up(numerator, denominator):\n",
    "\treturn np.ceil(numerator/denominator) * denominator\n",
    "\n",
    "\n",
    "def apply_min_ticks(ax, min_ticks=6):\n",
    "\tax.xaxis.set_major_locator(ticker.MaxNLocator(nbins=min_ticks, prune=None))\n",
    "\tax.yaxis.set_major_locator(ticker.MaxNLocator(nbins=min_ticks, prune=None))\n",
    "\n",
    "def specificity_score(y_true, y_pred):\n",
    "\ttn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\treturn tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "\n",
    "def img_from_df(df=None, path_out=None, filename=None):\n",
    "\tdf = df.map(lambda x: f\"{x:.4g}\" if isinstance(x, (int, float)) else x)\n",
    "\t####FORMAT INDEX FROM 1 TO N\n",
    "\tdf.index = range(1, len(df.index) + 1)\n",
    "\tdf.index.name = 'index'\n",
    "\t###ENSURE INDEX IS PRINTED\n",
    "\tdf.reset_index(inplace=True)\n",
    "\tfig, ax = plt.subplots(figsize=(df.shape[1] * 2, df.shape[0] * 0.25))\n",
    "\tax.axis('off')\n",
    "\n",
    "\ttable = ax.table(cellText=df.values, colLabels=df.columns, loc='center', cellLoc='center')\n",
    "\ttable.auto_set_font_size(False)\n",
    "\ttable.set_fontsize(12)\n",
    "\ttable.auto_set_column_width(col=list(range(len(df.columns))))\n",
    "\ttable.scale(1.2, 1.2)\n",
    "\n",
    "\tplt.savefig(os.path.join(path_out, f'{filename}.png'), bbox_inches='tight', dpi=300)\n",
    "\tplt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af4e4d4a-2c12-4f70-98e9-fc650205f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cart_gridsearch(X=None, y=None,\n",
    "                        importance_df=None,\n",
    "                        top_n_list=None,\n",
    "                        depth_list=None,\n",
    "                        path_out=None,\n",
    "                        label=None):\n",
    "    if top_n_list is None:\n",
    "        top_n_list = [7, 9, 13, 15]\n",
    "    if depth_list is None:\n",
    "        depth_list = [5, 6, 7]\n",
    "    \n",
    "    cart_results = []\n",
    "    top_features_sorted = list(importance_df.sort_values('Gain', ascending=False)['Feature'])\n",
    "    \n",
    "    for n in top_n_list:\n",
    "        if n > len(top_features_sorted):\n",
    "            continue\n",
    "        selected_feats = top_features_sorted[:n]\n",
    "        X_top = X[selected_feats]\n",
    "        \n",
    "        for depth in depth_list:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_top, y, test_size=0.2, stratify=y, random_state=42)\n",
    "            cart = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "            cart.fit(X_train, y_train)\n",
    "            y_pred = cart.predict(X_test)\n",
    "            \n",
    "            ##SAVE CART MODELS\n",
    "            model_filename = f'cart_model_{label}_top{n}_depth{depth}.pkl'\n",
    "            with open(os.path.join(path_out, model_filename), 'wb') as f:\n",
    "                pickle.dump(cart, f)\n",
    "            \n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            prec = precision_score(y_test, y_pred)\n",
    "            rec = recall_score(y_test, y_pred)\n",
    "            spec = specificity_score(y_test, y_pred)\n",
    "            \n",
    "            cart_results.append({\n",
    "                'label': label,\n",
    "                'top_n_features': n,\n",
    "                'max_depth': depth,\n",
    "                'accuracy': acc,\n",
    "                'precision': prec,\n",
    "                'recall': rec,\n",
    "                'specificity': spec,\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame from results\n",
    "    cart_df = pd.DataFrame(cart_results)\n",
    "    \n",
    "    # Add debugging\n",
    "    print(f\"cart_df shape: {cart_df.shape}\")\n",
    "    print(f\"cart_df columns: {cart_df.columns.tolist()}\")\n",
    "    if cart_df.empty:\n",
    "        print(\"WARNING: cart_df is empty!\")\n",
    "        print(f\"top_n_list: {top_n_list}\")\n",
    "        print(f\"depth_list: {depth_list}\")\n",
    "        print(f\"importance_df shape: {importance_df.shape}\")\n",
    "        print(f\"Number of features available: {len(top_features_sorted)}\")\n",
    "        return cart_df  # Return early if empty\n",
    "    \n",
    "    # Save CSV\n",
    "    cart_df.to_csv(os.path.join(path_out, f'cart_results_{label}.csv'), index=False)\n",
    "    \n",
    "    ###CREATE IMAGE OF THE GRID RESULTS\n",
    "    img_from_df(df=cart_df,\n",
    "                path_out=path_out,\n",
    "                filename=f'cart_results_{label}')\n",
    "    \n",
    "    ###HEATMAP\n",
    "    # Heatmaps\n",
    "    for metric, cmap in zip(['accuracy', 'precision', 'recall', 'specificity'],\n",
    "                            ['YlGnBu', 'Oranges', 'Purples', 'Blues']):\n",
    "        pivot = cart_df.pivot(index='max_depth', columns='top_n_features', values=metric)\n",
    "        plt.figure(figsize=(6, 6), constrained_layout=True)\n",
    "        sns.heatmap(pivot, annot=True, fmt=\".2f\", cmap=cmap, cbar_kws={'label': metric})\n",
    "        plt.title(f\"CART {metric.capitalize()} Heatmap - {label}\")\n",
    "        plt.xlabel(\"Top n Features\")\n",
    "        plt.ylabel(\"Max Depth\")\n",
    "        plt.savefig(os.path.join(path_out, f'xgb_heatmap_{metric}_{label}.png'), dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    return cart_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f28e4c1-44a3-4fda-b858-39f1d6cdc6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost model trained successfully\n",
      "importance_df shape: (6, 4)\n",
      "importance_df columns: ['Feature', 'Gain', 'Cumulative Gain', 'Cumulative Gain %']\n",
      "Number of features with importance: 6\n",
      "\n",
      "Top 10 important features:\n",
      "      Feature         Gain  Cumulative Gain  Cumulative Gain %\n",
      "4       total  1655.493042      1655.493042          35.416351\n",
      "3        male  1111.912964      2767.406006          59.203765\n",
      "5  population   919.013672      3686.419678          78.864440\n",
      "2      female   510.558655      4196.978333          89.786941\n",
      "0   age_group   410.789062      4607.767395          98.575047\n",
      "1      gender    66.607628      4674.375023         100.000000\n",
      "\n",
      "Available features: 6\n",
      "Requested top_n_list: [7, 9, 13, 15]\n",
      "WARNING: Only 6 features available, but requesting up to 15\n"
     ]
    }
   ],
   "source": [
    "def run_xgboost_gridsearch(X=None,\n",
    "\t\t\t\t\t\t   y=None,\n",
    "\t\t\t\t\t\t   param_grid=None,\n",
    "\t\t\t\t\t\t   path_out=None,\n",
    "\t\t\t\t\t\t   metric=None,\n",
    "\t\t\t\t\t\t   label='default'):\n",
    "\tif X is None or y is None or X.shape[0] == 0:\n",
    "\t\traise ValueError(\"Input features X or target y are empty or undefined.\")\n",
    "\n",
    "\txgb_grid_results = []\n",
    "\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\tfor max_depth, n_estimators in product(param_grid['max_depth'], param_grid['n_estimators']):\n",
    "\t\tmodel = XGBClassifier(\n",
    "\t\t\t#use_label_encoder=False,\n",
    "\t\t\teval_metric='logloss',\n",
    "\t\t\tmax_depth=max_depth,\n",
    "\t\t\tn_estimators=n_estimators,\n",
    "\t\t\trandom_state=42\n",
    "\t\t)\n",
    "\t\tmodel.fit(X_train, y_train)\n",
    "\t\ty_pred = model.predict(X_test)\n",
    "\t\tspec = specificity_score(y_test, y_pred)\n",
    "\n",
    "\t\txgb_grid_results.append({\n",
    "\t\t\t'filter': label,\n",
    "\t\t\t'max_depth': max_depth,\n",
    "\t\t\t'n_estimators': n_estimators,\n",
    "\t\t\t'accuracy': accuracy_score(y_test, y_pred),\n",
    "\t\t\t'precision': precision_score(y_test, y_pred),\n",
    "\t\t\t'recall': recall_score(y_test, y_pred),\n",
    "\t\t\t'specificity':spec,\n",
    "\t\t})\n",
    "\n",
    "\t# Save grid results\n",
    "\txgb_df = pd.DataFrame(xgb_grid_results)\n",
    "\txgb_df.to_csv(os.path.join(path_out, f'xgb_grid_results_{label}.csv'), index=False)\n",
    "\n",
    "\t###CREATE IMAGE OF THE GRID RESULTS\n",
    "\timg_from_df(df=xgb_df,\n",
    "\t\t\t\tpath_out=path_out,\n",
    "\t\t\t\tfilename='xgb_grid_results_table')\n",
    "\n",
    "\t# Heatmaps\n",
    "\tfor metric, cmap in zip(['accuracy', 'precision', 'recall', 'specificity'], ['YlGnBu', 'Oranges', 'Purples', 'Blues']):\n",
    "\t\tpivot = xgb_df.pivot(index='max_depth', columns='n_estimators', values=metric)\n",
    "\t\tplt.figure(figsize=(6, 6), constrained_layout=True)\n",
    "\t\tsns.heatmap(pivot, annot=True, fmt=\".2f\", cmap=cmap, cbar_kws={'label': metric})\n",
    "\t\tplt.title(f\"XGBoost {metric.capitalize()} Heatmap - {label}\")\n",
    "\t\tplt.xlabel(\"n_estimators\")\n",
    "\t\tplt.ylabel(\"max_depth\")\n",
    "\t\tplt.savefig(os.path.join(path_out, f'xgb_heatmap_{metric}_{label}.png'), dpi=300)\n",
    "\t\tplt.close()\n",
    "\n",
    "\t# Train best model\n",
    "\tbest = xgb_df.sort_values(by=metric, ascending=False).iloc[0]\n",
    "\tbest_model = XGBClassifier(\n",
    "\t\t#use_label_encoder=False,\n",
    "\t\teval_metric='logloss',\n",
    "\t\tmax_depth=int(best['max_depth']),\n",
    "\t\tn_estimators=int(best['n_estimators']),\n",
    "\t\trandom_state=42\n",
    "\t)\n",
    "\tbest_model.fit(X_train, y_train)\n",
    "\n",
    "\t# SHAP\n",
    "\texplainer = shap.Explainer(best_model)\n",
    "\tshap_values = explainer(X_test)\n",
    "\tshap.plots.beeswarm(shap_values, max_display=15, order=shap_values.abs.max(0), show=False)\n",
    "\tplt.savefig(os.path.join(path_out, f'SHAP_best_{label}.png'), dpi=300, bbox_inches='tight')\n",
    "\tplt.close()\n",
    "\n",
    "\t# Feature importance\n",
    "\tbooster = best_model.get_booster()\n",
    "\tfig, ax = plt.subplots(figsize=(12, 8))\n",
    "\tplot_importance(booster, importance_type='gain', max_num_features=15, ax=ax)\n",
    "\tplt.title(f\"Top Features by Gain (Best XGBoost) - {label}\")\n",
    "\tplt.savefig(os.path.join(path_out, f'top_features_by_gain_best_{label}.png'), dpi=300, bbox_inches='tight')\n",
    "\tplt.close()\n",
    "\n",
    "\timportance_df = booster.get_score(importance_type='gain')\n",
    "\timportance_df_df = pd.DataFrame(list(importance_df.items()), columns=['Feature', 'Gain'])\n",
    "\timportance_df_df = importance_df_df.sort_values(by='Gain', ascending=False)\n",
    "\timportance_df_df['Cumulative Gain'] = importance_df_df['Gain'].cumsum()\n",
    "\timportance_df_df['Cumulative Gain %'] = importance_df_df['Cumulative Gain'] / importance_df_df['Gain'].sum() *100\n",
    "\timportance_df_df.to_csv(os.path.join(path_out, 'importance_df.csv'), index=False)\n",
    "\n",
    "\t###CREATE IMAGE OF THE IMPORTANCE TABLE\n",
    "\timg_from_df(df=importance_df_df,\n",
    "\t\t\t\tpath_out=path_out,\n",
    "\t\t\t\tfilename='importance_df_table')\n",
    "\n",
    "\treturn best_model, importance_df_df\n",
    "    \n",
    "print(f\"\\nXGBoost model trained successfully\")\n",
    "print(f\"importance_df shape: {importance_df.shape}\")\n",
    "print(f\"importance_df columns: {importance_df.columns.tolist()}\")\n",
    "print(f\"Number of features with importance: {len(importance_df)}\")\n",
    "print(\"\\nTop 10 important features:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Check if we have enough features\n",
    "available_features = len(importance_df)\n",
    "print(f\"\\nAvailable features: {available_features}\")\n",
    "print(f\"Requested top_n_list: [7, 9, 13, 15]\")\n",
    "if available_features < 15:\n",
    "    print(f\"WARNING: Only {available_features} features available, but requesting up to 15\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfaf686-58f2-4d29-b01a-187bffec1e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "046f64b0-1694-4ada-b7af-95c46645777a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in X:\n",
      "['region', 'date', 'age_group', 'gender', 'weather_event', 'warning_phenomenon', 'warning_severity', 'warning_severity_numeric', 'counties_in_region', 'county_weight', 'female', 'male', 'total', 'population', 'log_population', 'month', 'season', 'is_winter', 'is_spring', 'is_summer', 'is_autumn', 'orange_warning', 'red_warning', 'yellow_warning', 'orange_warning_lag', 'red_warning_lag', 'cold_weather', 'wind_weather', 'precipitation', 'heat_weather', 'no_adverse_weather', 'cold_lag', 'wind_lag', 'precip_lag', 'heat_lag']\n",
      "\n",
      "Data types:\n",
      "region                       object\n",
      "date                         object\n",
      "age_group                    object\n",
      "gender                       object\n",
      "weather_event               float64\n",
      "warning_phenomenon           object\n",
      "warning_severity             object\n",
      "warning_severity_numeric    float64\n",
      "counties_in_region            int64\n",
      "county_weight               float64\n",
      "female                      float64\n",
      "male                        float64\n",
      "total                       float64\n",
      "population                  float64\n",
      "log_population              float64\n",
      "month                         int64\n",
      "season                       object\n",
      "is_winter                     int64\n",
      "is_spring                     int64\n",
      "is_summer                     int64\n",
      "is_autumn                     int64\n",
      "orange_warning                int64\n",
      "red_warning                   int64\n",
      "yellow_warning                int64\n",
      "orange_warning_lag          float64\n",
      "red_warning_lag             float64\n",
      "cold_weather                  int64\n",
      "wind_weather                  int64\n",
      "precipitation                 int64\n",
      "heat_weather                  int64\n",
      "no_adverse_weather            int64\n",
      "cold_lag                    float64\n",
      "wind_lag                    float64\n",
      "precip_lag                  float64\n",
      "heat_lag                    float64\n",
      "dtype: object\n",
      "\n",
      "Object columns to encode: ['region', 'age_group', 'gender', 'warning_phenomenon', 'warning_severity', 'season']\n",
      "\n",
      "Data types after processing:\n",
      "region                        int64\n",
      "age_group                     int64\n",
      "gender                        int64\n",
      "weather_event               float64\n",
      "warning_phenomenon            int64\n",
      "warning_severity              int64\n",
      "warning_severity_numeric    float64\n",
      "counties_in_region            int64\n",
      "county_weight               float64\n",
      "female                      float64\n",
      "male                        float64\n",
      "total                       float64\n",
      "population                  float64\n",
      "log_population              float64\n",
      "month                         int64\n",
      "season                        int64\n",
      "is_winter                     int64\n",
      "is_spring                     int64\n",
      "is_summer                     int64\n",
      "is_autumn                     int64\n",
      "orange_warning                int64\n",
      "red_warning                   int64\n",
      "yellow_warning                int64\n",
      "orange_warning_lag          float64\n",
      "red_warning_lag             float64\n",
      "cold_weather                  int64\n",
      "wind_weather                  int64\n",
      "precipitation                 int64\n",
      "heat_weather                  int64\n",
      "no_adverse_weather            int64\n",
      "cold_lag                    float64\n",
      "wind_lag                    float64\n",
      "precip_lag                  float64\n",
      "heat_lag                    float64\n",
      "dtype: object\n",
      "\n",
      "Any remaining object columns: Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
      "\n",
      "[97119 rows x 0 columns]\n"
     ]
    }
   ],
   "source": [
    "X = merged_glass.drop('hip_fracture_count', axis=1)\n",
    "y = merged_glass['hip_fracture_count']\n",
    "\n",
    "# Binary classification: fracture vs no fracture\n",
    "y_binary = (y > 0).astype(int)\n",
    "\n",
    "print(\"Columns in X:\")\n",
    "print(X.columns.tolist())\n",
    "print(\"\\nData types:\")\n",
    "print(X.dtypes)\n",
    "\n",
    "# Option 1: Drop the date column and encode everything else\n",
    "X_processed = X.copy()\n",
    "\n",
    "# Drop date column if it exists\n",
    "if 'date' in X_processed.columns:\n",
    "    X_processed = X_processed.drop('date', axis=1)\n",
    "\n",
    "# Check for any remaining object columns\n",
    "object_cols = X_processed.select_dtypes(include=['object']).columns\n",
    "print(f\"\\nObject columns to encode: {object_cols.tolist()}\")\n",
    "\n",
    "# Encode all object columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "for col in object_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_processed[col] = le.fit_transform(X_processed[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Verify all columns are numeric\n",
    "print(\"\\nData types after processing:\")\n",
    "print(X_processed.dtypes)\n",
    "print(f\"\\nAny remaining object columns: {X_processed.select_dtypes(include=['object'])}\")\n",
    "\n",
    "dfu = merged_glass[merged_glass['hip_fracture_count'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5b3ea1e-150a-4ecd-9989-ce24c0d59cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost model trained successfully\n",
      "importance_df shape: (6, 4)\n",
      "Number of features with importance: 6\n",
      "\n",
      "Top features:\n",
      "      Feature         Gain  Cumulative Gain  Cumulative Gain %\n",
      "4       total  1655.493042      1655.493042          35.416351\n",
      "3        male  1111.912964      2767.406006          59.203765\n",
      "5  population   919.013672      3686.419678          78.864440\n",
      "2      female   510.558655      4196.978333          89.786941\n",
      "0   age_group   410.789062      4607.767395          98.575047\n",
      "1      gender    66.607628      4674.375023         100.000000\n",
      "\n",
      "Adjusted top_n_list from [7, 9, 13, 15] to [3, 4, 5, 6]\n",
      "cart_df shape: (12, 7)\n",
      "cart_df columns: ['label', 'top_n_features', 'max_depth', 'accuracy', 'precision', 'recall', 'specificity']\n",
      "\n",
      "CART grid search completed. Generated 12 models.\n",
      "\n",
      "Best efficient CART model:\n",
      "label                  dfk\n",
      "top_n_features           3\n",
      "max_depth                5\n",
      "accuracy          0.994852\n",
      "precision              1.0\n",
      "recall            0.984147\n",
      "specificity            1.0\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- age_group\n- cold_lag\n- cold_weather\n- counties_in_region\n- county_weight\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 87\u001b[0m\n\u001b[1;32m     84\u001b[0m plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m####generate predictions\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcart_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_processed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m merged_glass[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_outcome\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_glass[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhip_fracture_count\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m#apply predictions to df\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/msc/lib/python3.12/site-packages/sklearn/tree/_classes.py:530\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \n\u001b[1;32m    509\u001b[0m \u001b[38;5;124;03mFor a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;124;03m    The predicted classes, or the predict values.\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    529\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 530\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m    532\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/msc/lib/python3.12/site-packages/sklearn/tree/_classes.py:489\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     ensure_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    498\u001b[0m     X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc\n\u001b[1;32m    499\u001b[0m ):\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/msc/lib/python3.12/site-packages/sklearn/utils/validation.py:2919\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvalidate_data\u001b[39m(\n\u001b[1;32m   2836\u001b[0m     _estimator,\n\u001b[1;32m   2837\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2843\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m   2844\u001b[0m ):\n\u001b[1;32m   2845\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[1;32m   2846\u001b[0m \n\u001b[1;32m   2847\u001b[0m \u001b[38;5;124;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2917\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m   2918\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2919\u001b[0m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2920\u001b[0m     tags \u001b[38;5;241m=\u001b[39m get_tags(_estimator)\n\u001b[1;32m   2921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n",
      "File \u001b[0;32m~/anaconda3/envs/msc/lib/python3.12/site-packages/sklearn/utils/validation.py:2777\u001b[0m, in \u001b[0;36m_check_feature_names\u001b[0;34m(estimator, X, reset)\u001b[0m\n\u001b[1;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m   2775\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 2777\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- age_group\n- cold_lag\n- cold_weather\n- counties_in_region\n- county_weight\n- ...\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "### MODELLING ASSESSMENT\n",
    "##########\n",
    "###RUN XGBOOST ASSESSMENT\n",
    "### XGBoost hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [5, 6, 10, 20],\n",
    "    'n_estimators': [50, 100, 150]\n",
    "}\n",
    "metric = 'specificity'\n",
    "\n",
    "##RUN XGBOOST AND GET BEST MODEL\n",
    "best_model, importance_df = run_xgboost_gridsearch(X=X_processed,\n",
    "                                                   y=y_binary,\n",
    "                                                   param_grid=param_grid,\n",
    "                                                   metric=metric,\n",
    "                                                   path_out=pathdic['results'],\n",
    "                                                   label='dfk')\n",
    "\n",
    "# Debug XGBoost output\n",
    "print(f\"\\nXGBoost model trained successfully\")\n",
    "print(f\"importance_df shape: {importance_df.shape}\")\n",
    "print(f\"Number of features with importance: {len(importance_df)}\")\n",
    "print(\"\\nTop features:\")\n",
    "print(importance_df)\n",
    "\n",
    "###save best model to pkl\n",
    "pickle.dump(best_model,\n",
    "            open(os.path.join(pathdic['results'], 'XGB_best_model.pkl'), 'wb'))\n",
    "\n",
    "# CRITICAL FIX: Adjust top_n_list based on available features\n",
    "available_features = len(importance_df)\n",
    "if available_features <= 6:\n",
    "    # For 6 or fewer features, use a more appropriate range\n",
    "    top_n_list = [3, 4, 5, 6][:available_features]  # This gives [3, 4, 5, 6] for 6 features\n",
    "else:\n",
    "    # Original list for datasets with more features\n",
    "    top_n_list = [7, 9, 13, 15]\n",
    "\n",
    "# Filter to valid values only\n",
    "valid_top_n_list = [n for n in top_n_list if n <= available_features]\n",
    "print(f\"\\nAdjusted top_n_list from [7, 9, 13, 15] to {valid_top_n_list}\")\n",
    "\n",
    "###BASED ON THE BEST XGBOOST MODEL RUN A CART ANALYSIS\n",
    "cart_df = run_cart_gridsearch(X=X_processed,\n",
    "                              y=y_binary,\n",
    "                              importance_df=importance_df,\n",
    "                              top_n_list=valid_top_n_list,  # Use the adjusted list\n",
    "                              depth_list=[5, 6, 7],\n",
    "                              path_out=pathdic['results'],\n",
    "                              label='dfk')\n",
    "\n",
    "# Continue with the rest of your code...\n",
    "if cart_df.empty:\n",
    "    print(\"ERROR: cart_df is still empty after adjustment!\")\n",
    "else:\n",
    "    print(f\"\\nCART grid search completed. Generated {len(cart_df)} models.\")\n",
    "    \n",
    "    best_cart = cart_df.sort_values(\n",
    "        by=[metric, 'top_n_features', 'max_depth'],\n",
    "        ascending=[False, True, True]\n",
    "    ).iloc[0]\n",
    "    print(\"\\nBest efficient CART model:\")\n",
    "    print(best_cart)\n",
    "    \n",
    "filename = f\"cart_model_{best_cart['label']}_top{int(best_cart['top_n_features'])}_depth{int(best_cart['max_depth'])}.pkl\"\n",
    "filepath = os.path.join(pathdic['results'], filename)\n",
    "\n",
    "# Load that specific CART model\n",
    "with open(filepath, 'rb') as f:\n",
    "    cart_model = pickle.load(f)\n",
    "\n",
    "###GET THE TOP FEATURES ONLY\n",
    "selected_feats = importance_df.sort_values(\n",
    "\t'Gain',\n",
    "\tascending=False).head(int(best_cart['top_n_features']))['Feature'].tolist()\n",
    "X_u = dfu[selected_feats]\n",
    "\n",
    "###PLOT THE  BEST MODEL\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "plot_tree(cart_model, feature_names=selected_feats, class_names=True, filled=True, max_depth=int(best_cart['max_depth']))\n",
    "plt.title(f\"CART Tree - Top {int(best_cart['top_n_features'])} Features - Depth {int(best_cart['max_depth'])}\")\n",
    "plt.savefig(os.path.join(pathdic['results'], f'cart_tree_top{int(best_cart['top_n_features'])}_depth{int(best_cart['max_depth'])}.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "####generate predictions\n",
    "y_pred = cart_model.predict(X_processed)\n",
    "merged_glass['predicted_outcome'] = merged_glass['hip_fracture_count']\n",
    "#apply predictions to df\n",
    "merged_glass.loc[merged_glass['hip_fracture_count'].isna(), 'predicted_outcome'] = y_pred\n",
    "###ADD GROUND TRUTH DATA TO PREDICTED\n",
    "##save the df\n",
    "merged_glass.to_csv(os.path.join(pathdic['results'], 'predictions_df.csv'))\n",
    "pred_series = merged_glass['predicted_outcome']\n",
    "##save outcomes to txt file\n",
    "with open(os.path.join(pathdic['results'], 'cart_prediction.txt'), 'w') as f:\n",
    "\tfor idx, val in pred_series.items():\n",
    "\t\tf.write(f\"{idx}: {val}\\n\")\n",
    "#X_u.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be56407-7b3b-4370-a311-f7ea64b43b38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
